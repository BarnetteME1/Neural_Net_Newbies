{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Lasagne Example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Manual Run"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "import cPickle as pickle\n",
      "import gzip\n",
      "import itertools\n",
      "import urllib\n",
      "\n",
      "import numpy as np\n",
      "import lasagne\n",
      "import theano\n",
      "import theano.tensor as T"
     ],
     "language": "python",
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "DATA_URL = 'http://deeplearning.net/data/mnist/mnist.pkl.gz'\n",
      "DATA_FILENAME = 'data/mnist.pkl.gz'\n",
      "\n",
      "NUM_EPOCHS = 500\n",
      "BATCH_SIZE = 600\n",
      "NUM_HIDDEN_UNITS = 512\n",
      "LEARNING_RATE = 0.01\n",
      "MOMENTUM = 0.9"
     ],
     "language": "python",
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "urllib.urlretrieve(DATA_URL, DATA_FILENAME)\n",
      "with gzip.open(DATA_FILENAME, 'rb') as f:\n",
      "    data = pickle.load(f)"
     ],
     "language": "python",
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "X_train, y_train = data[0]\n",
      "X_valid, y_valid = data[1]\n",
      "X_test, y_test = data[2]"
     ],
     "language": "python",
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "dataset = dict(\n",
      "    X_train=theano.shared(lasagne.utils.floatX(X_train)),\n",
      "    y_train=T.cast(theano.shared(y_train), 'int32'),\n",
      "    X_valid=theano.shared(lasagne.utils.floatX(X_valid)),\n",
      "    y_valid=T.cast(theano.shared(y_valid), 'int32'),\n",
      "    X_test=theano.shared(lasagne.utils.floatX(X_test)),\n",
      "    y_test=T.cast(theano.shared(y_test), 'int32'),\n",
      "    num_examples_train=X_train.shape[0],\n",
      "    num_examples_valid=X_valid.shape[0],\n",
      "    num_examples_test=X_test.shape[0],\n",
      "    input_dim=X_train.shape[1],\n",
      "    output_dim=10,\n",
      "    )"
     ],
     "language": "python",
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "input_dim = dataset[\"input_dim\"]\n",
      "output_dim = dataset[\"output_dim\"]\n",
      "batch_size=BATCH_SIZE\n",
      "num_hidden_units=NUM_HIDDEN_UNITS"
     ],
     "language": "python",
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "l_in = lasagne.layers.InputLayer(\n",
      "    shape=(batch_size, input_dim),\n",
      "    )\n",
      "l_hidden1 = lasagne.layers.DenseLayer(\n",
      "    l_in,\n",
      "    num_units=num_hidden_units,\n",
      "    nonlinearity=lasagne.nonlinearities.rectify,\n",
      "    )\n",
      "l_hidden1_dropout = lasagne.layers.DropoutLayer(\n",
      "    l_hidden1,\n",
      "    p=0.5,\n",
      "    )\n",
      "l_hidden2 = lasagne.layers.DenseLayer(\n",
      "    l_hidden1_dropout,\n",
      "    num_units=num_hidden_units,\n",
      "    nonlinearity=lasagne.nonlinearities.rectify,\n",
      "    )\n",
      "l_hidden2_dropout = lasagne.layers.DropoutLayer(\n",
      "    l_hidden2,\n",
      "    p=0.5,\n",
      "    )\n",
      "l_out = lasagne.layers.DenseLayer(\n",
      "    l_hidden2_dropout,\n",
      "    num_units=output_dim,\n",
      "    nonlinearity=lasagne.nonlinearities.softmax,\n",
      "    )"
     ],
     "language": "python",
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "Softmax.0"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "l_out.get_output()"
     ],
     "language": "python",
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "output_layer = l_out\n",
      "X_tensor_type=T.matrix\n",
      "learning_rate=LEARNING_RATE\n",
      "momentum=MOMENTUM"
     ],
     "language": "python",
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "batch_index = T.iscalar('batch_index')\n",
      "X_batch = X_tensor_type('x')\n",
      "y_batch = T.ivector('y')\n",
      "batch_slice = slice(batch_index * batch_size, (batch_index + 1) * batch_size)"
     ],
     "language": "python",
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "def loss(output):\n",
      "    return -T.mean(T.log(output)[T.arange(y_batch.shape[0]), y_batch])"
     ],
     "language": "python",
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "loss_train = loss(output_layer.get_output(X_batch))\n",
      "loss_eval = loss(output_layer.get_output(X_batch, deterministic=True))"
     ],
     "language": "python",
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "pred = T.argmax(\n",
      "    output_layer.get_output(X_batch, deterministic=True), axis=1)\n",
      "accuracy = T.mean(T.eq(pred, y_batch))"
     ],
     "language": "python",
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/Lasagne-0.1.dev0-py2.7.egg/lasagne/layers/helper.py:52: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`.\n",
        "  warnings.warn(\"get_all_layers() has been changed to return layers in \"\n"
       ]
      }
     ],
     "input": [
      "all_params = lasagne.layers.get_all_params(output_layer)\n",
      "updates = lasagne.updates.nesterov_momentum(\n",
      "    loss_train, all_params, learning_rate, momentum)"
     ],
     "language": "python",
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "iter_train = theano.function(\n",
      "    [batch_index], loss_train,\n",
      "    updates=updates,\n",
      "    givens={\n",
      "        X_batch: dataset['X_train'][batch_slice],\n",
      "        y_batch: dataset['y_train'][batch_slice],\n",
      "        },\n",
      "    )\n",
      "\n",
      "iter_valid = theano.function(\n",
      "    [batch_index], [loss_eval, accuracy],\n",
      "    givens={\n",
      "        X_batch: dataset['X_valid'][batch_slice],\n",
      "        y_batch: dataset['y_valid'][batch_slice],\n",
      "        },\n",
      "    )\n",
      "\n",
      "iter_test = theano.function(\n",
      "    [batch_index], [loss_eval, accuracy],\n",
      "    givens={\n",
      "        X_batch: dataset['X_test'][batch_slice],\n",
      "        y_batch: dataset['y_test'][batch_slice],\n",
      "        },\n",
      "    )"
     ],
     "language": "python",
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "iter_funcs = dict(\n",
      "    train=iter_train,\n",
      "    valid=iter_valid,\n",
      "    test=iter_test,\n",
      "    )"
     ],
     "language": "python",
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "num_batches_train = dataset['num_examples_train'] // batch_size\n",
      "num_batches_valid = dataset['num_examples_valid'] // batch_size\n",
      "num_batches_test = dataset['num_examples_test'] // batch_size"
     ],
     "language": "python",
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "def train(iter_funcs, dataset, batch_size=BATCH_SIZE):\n",
      "    num_batches_train = dataset['num_examples_train'] // batch_size\n",
      "    num_batches_valid = dataset['num_examples_valid'] // batch_size\n",
      "    num_batches_test = dataset['num_examples_test'] // batch_size\n",
      "\n",
      "    for epoch in itertools.count(1):\n",
      "        batch_train_losses = []\n",
      "        for b in range(num_batches_train):\n",
      "            batch_train_loss = iter_funcs['train'](b)\n",
      "            batch_train_losses.append(batch_train_loss)\n",
      "\n",
      "        avg_train_loss = np.mean(batch_train_losses)\n",
      "\n",
      "        batch_valid_losses = []\n",
      "        batch_valid_accuracies = []\n",
      "        for b in range(num_batches_valid):\n",
      "            batch_valid_loss, batch_valid_accuracy = iter_funcs['valid'](b)\n",
      "            batch_valid_losses.append(batch_valid_loss)\n",
      "            batch_valid_accuracies.append(batch_valid_accuracy)\n",
      "\n",
      "        avg_valid_loss = np.mean(batch_valid_losses)\n",
      "        avg_valid_accuracy = np.mean(batch_valid_accuracies)\n",
      "\n",
      "        yield {\n",
      "            'number': epoch,\n",
      "            'train_loss': avg_train_loss,\n",
      "            'valid_loss': avg_valid_loss,\n",
      "            'valid_accuracy': avg_valid_accuracy,\n",
      "            }"
     ],
     "language": "python",
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "num_epochs = 10"
     ],
     "language": "python",
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 1 of 10\n",
        "  training loss:\t\t1.333131\n",
        "  validation loss:\t\t0.462975\n",
        "  validation accuracy:\t\t87.49 %\n",
        "Epoch 2 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.586310\n",
        "  validation loss:\t\t0.326112\n",
        "  validation accuracy:\t\t90.57 %\n",
        "Epoch 3 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.460305\n",
        "  validation loss:\t\t0.279471\n",
        "  validation accuracy:\t\t91.79 %\n",
        "Epoch 4 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.401532\n",
        "  validation loss:\t\t0.248660\n",
        "  validation accuracy:\t\t92.58 %\n",
        "Epoch 5 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.361652\n",
        "  validation loss:\t\t0.225353\n",
        "  validation accuracy:\t\t93.34 %\n",
        "Epoch 6 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.330177\n",
        "  validation loss:\t\t0.209012\n",
        "  validation accuracy:\t\t93.83 %\n",
        "Epoch 7 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.308497\n",
        "  validation loss:\t\t0.194022\n",
        "  validation accuracy:\t\t94.28 %\n",
        "Epoch 8 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.289160\n",
        "  validation loss:\t\t0.181664\n",
        "  validation accuracy:\t\t94.70 %\n",
        "Epoch 9 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.267791\n",
        "  validation loss:\t\t0.170311\n",
        "  validation accuracy:\t\t94.99 %\n",
        "Epoch 10 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.252842\n",
        "  validation loss:\t\t0.161186\n",
        "  validation accuracy:\t\t95.34 %\n"
       ]
      }
     ],
     "input": [
      "for epoch in train(iter_funcs, dataset):\n",
      "    print(\"Epoch %d of %d\" % (epoch['number'], num_epochs))\n",
      "    print(\"  training loss:\\t\\t%.6f\" % epoch['train_loss'])\n",
      "    print(\"  validation loss:\\t\\t%.6f\" % epoch['valid_loss'])\n",
      "    print(\"  validation accuracy:\\t\\t%.2f %%\" %\n",
      "          (epoch['valid_accuracy'] * 100))\n",
      "\n",
      "    if epoch['number'] >= num_epochs:\n",
      "        break\n",
      "\n",
      "result= output_layer"
     ],
     "language": "python",
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Script Run"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "%load_ext autoreload"
     ],
     "language": "python",
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "%autoreload 2"
     ],
     "language": "python",
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "import lib.lasagne_mnist as lasagne_mnist"
     ],
     "language": "python",
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting training...\n",
        "Epoch 1 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t1.337511\n",
        "  validation loss:\t\t0.453990\n",
        "  validation accuracy:\t\t87.86 %\n",
        "Epoch 2 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.580036\n",
        "  validation loss:\t\t0.324367\n",
        "  validation accuracy:\t\t90.60 %\n",
        "Epoch 3 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.463588\n",
        "  validation loss:\t\t0.276408\n",
        "  validation accuracy:\t\t91.95 %\n",
        "Epoch 4 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.398257\n",
        "  validation loss:\t\t0.247057\n",
        "  validation accuracy:\t\t92.80 %\n",
        "Epoch 5 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.359415\n",
        "  validation loss:\t\t0.225045\n",
        "  validation accuracy:\t\t93.38 %\n",
        "Epoch 6 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.330612\n",
        "  validation loss:\t\t0.207095\n",
        "  validation accuracy:\t\t93.85 %\n",
        "Epoch 7 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.309475\n",
        "  validation loss:\t\t0.192656\n",
        "  validation accuracy:\t\t94.33 %\n",
        "Epoch 8 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.285780\n",
        "  validation loss:\t\t0.179702\n",
        "  validation accuracy:\t\t94.79 %\n",
        "Epoch 9 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.268906\n",
        "  validation loss:\t\t0.170092\n",
        "  validation accuracy:\t\t95.00 %\n",
        "Epoch 10 of 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  training loss:\t\t0.253436\n",
        "  validation loss:\t\t0.160809\n",
        "  validation accuracy:\t\t95.28 %\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "<lasagne.layers.dense.DenseLayer at 0x115a59bd0>"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "lasagne_mnist.main(10)"
     ],
     "language": "python",
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {
  "name": "",
  "signature": "sha256:7ab012cb829fff3f88b65491a6ea053c0247bb77de6ca610c1027e99fb6879ec"
 },
 "nbformat": 3,
 "nbformat_minor": 0
}